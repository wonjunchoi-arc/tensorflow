{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "가위바위보, 허리디스크,목디스크.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO7yjRJXHWX7/FK1ee6JmiK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wonjunchoi-arc/tensorflow/blob/main/%EA%B0%80%EC%9C%84%EB%B0%94%EC%9C%84%EB%B3%B4%2C_%ED%97%88%EB%A6%AC%EB%94%94%EC%8A%A4%ED%81%AC%2C%EB%AA%A9%EB%94%94%EC%8A%A4%ED%81%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTYcbW6A7rB0"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "from cv2 import ml_KNearest\n",
        "import cv2 \n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "max_num_hands = 1\n",
        "gesture = {\n",
        "0:'fist',1:'one',2:'two',3:'three',4:'four',5:'five',6:'six',\n",
        "            7:'rock', 8:'spiderman', 9:'yeah', 10:'ok',\n",
        "\n",
        "}\n",
        "\n",
        "rps_gesture = {0: 'rock', 5:'paper', 9:'scissors'}\n",
        "\n",
        "#Media\n",
        "mp_hands = mp.solutions.hands\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "hands = mp_hands.Hands(\n",
        "    max_num_hands =max_num_hands,\n",
        "    min_detection_confidence = 0.5,\n",
        "    min_tracking_confidence = 0.5,\n",
        ")\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "#Gesture R model\n",
        "file =np.genfromtxt('../down/gesture_train.csv',delimiter=',')\n",
        "angle =file[:,:-1].astype(np.float32)\n",
        "label =file[:,-1].astype(np.float32)\n",
        "print(angle)\n",
        "print(label)\n",
        "knn = ml_KNearest.create()\n",
        "# knn = KNeighborsClassifier(n_neighbors=2)\n",
        "# knn.fit(angle,label)/\n",
        "knn.train(angle, cv2.ml.ROW_SAMPLE,label)\n",
        "\n",
        "\n",
        "cap = cv2.imread('../down/0.png')\n",
        "\n",
        "if cap is not None:\n",
        "    cap= cv2.flip(cap, 1)\n",
        "    cap = cv2.cvtColor(cap,cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    results =hands.process(cap)\n",
        "\n",
        "    cap =cv2.cvtColor(cap, cv2.COLOR_RGB2BGR)\n",
        "    cv2_imshow(cap)\n",
        "else:\n",
        "    print('No image file.')\n",
        "print(len(results.multi_hand_landmarks))\n",
        "\n",
        "if results.multi_hand_landmarks is not None:\n",
        "    for res in results.multi_hand_landmarks:\n",
        "        joint =np.zeros((21,3))\n",
        "        for j, lm in enumerate(res.landmark):\n",
        "            joint[j] = [lm.x, lm.y, lm.z]\n",
        "v1 = joint[[0,1,2,3,0,5,6,7,0,9,10,11,0,13,14,15,0,17,18,19],:]\n",
        "v2 =joint[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],:]\n",
        "v = v2 - v1\n",
        "v= v/ np.linalg.norm(v, axis=1)[:,np.newaxis]\n",
        "\n",
        "\n",
        "angle =np.arccos(np.einsum('nt,nt->n',\n",
        "v[[0,1,2,4,5,6,8,9,10,12,13,14,16,17,18],:],\n",
        "v[[1,2,3,5,6,7,9,10,11,13,14,15,7,18,19],:]))\n",
        "\n",
        "\n",
        "angle =np.degrees(angle)\n",
        "\n",
        "\n",
        "\n",
        "data =np.array([angle], dtype=np.float32)\n",
        "print(data)\n",
        "ret, results, neighbors, dist = knn.findNearest(data, 3)\n",
        "idx =int(results[0][0])\n",
        "print(ret)\n",
        "print(results)\n",
        "print(neighbors)\n",
        "print(dist)\n",
        "\n",
        "\n",
        "\n",
        "#Draw\n",
        "if idx in rps_gesture.keys():\n",
        "    cv2.putText(cap, text=rps_gesture[idx].upper(),\n",
        "                org=(int(res.landmark[0].x * cap.shape[1])\n",
        "    , int(res.landmark[0].y * cap.shape[0] + 20)), fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
        "    fontScale=1, color=(255,255,255), thickness=2)\n",
        "\n",
        "print('여기까지 실행')\n",
        "\n",
        "mp_drawing.draw_landmarks(cap, res, mp_hands.HAND_CONNECTIONS)\n",
        "cv2_imshow(cap)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "on_YUdoorIWh"
      },
      "source": [
        "!pip  install mediapipe\n",
        "from google.colab.patches import cv2_imshow\n",
        "from cv2 import ml_KNearest\n",
        "import cv2 \n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "import csv\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "max_num_human = 1\n",
        "discs_pose = {\n",
        "0:'Good_Pose',1:'NO!',2:'neck_discs',\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "#Media\n",
        "mp_pose = mp.solutions.pose\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "pose = mp_pose.Pose(\n",
        "     model_complexity=2,\n",
        "    min_detection_confidence = 0.5,\n",
        "    min_tracking_confidence = 0.5,\n",
        ")\n",
        "\n",
        "#Gesture R model\n",
        "file =np.genfromtxt('../down/discs_train.csv',delimiter=',')\n",
        "angle =file[:,:-1].astype(np.float32)\n",
        "label =file[:,-1].astype(np.float32)\n",
        "\n",
        "knn = ml_KNearest.create()\n",
        "knn.train(angle, cv2.ml.ROW_SAMPLE,label)\n",
        "\n",
        "cap = cv2.imread('../down/nor/5.jpg')\n",
        "\n",
        "if cap is not None:\n",
        "    cap= cv2.flip(cap, 1)\n",
        "    cap = cv2.cvtColor(cap,cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    results =pose.process(cap)\n",
        "\n",
        "    cap =cv2.cvtColor(cap, cv2.COLOR_RGB2BGR)\n",
        "    cv2_imshow(cap)\n",
        "else:\n",
        "    print('No image file.')\n",
        "\n",
        "a=[]\n",
        "a.append(results.pose_landmarks)\n",
        "print(len(a))\n",
        "\n",
        "if results.pose_landmarks is not None:\n",
        "     for res in a:\n",
        "         joint =np.zeros((33,4))\n",
        "         for j, lm in enumerate(res.landmark):\n",
        "            joint[j] = [lm.x, lm.y, lm.z, lm.visibility]\n",
        "\n",
        "v1 = joint[[11,11,12,12,11,12,23],:]\n",
        "v2 =joint[[0,7,0,7,23,24,24],:]\n",
        "v = v2 - v1\n",
        "v= v/ np.linalg.norm(v, axis=1)[:,np.newaxis]\n",
        "\n",
        "\n",
        "angle =np.arccos(np.einsum('nt,nt->n',\n",
        "v[[0,1,2,3,4,5],:],\n",
        "v[[1,2,3,4,5,6],:]))\n",
        "\n",
        "angle =np.degrees(angle)\n",
        "\n",
        "# print(type(angle))\n",
        "\n",
        "# df = pd.DataFrame(angle)\n",
        "# df.loc[6] = [1]\n",
        "# df=df.transpose()\n",
        "# print(df)\n",
        "\n",
        "# df.to_csv('../down/discs_train.csv',mode='a', index=False,header = False)\n",
        "\n",
        "data =np.array([angle], dtype=np.float32)\n",
        "ret, results, neighbors, dist = knn.findNearest(data, 1)\n",
        "idx =int(results[0][0])\n",
        "\n",
        "\n",
        "\n",
        "#Draw\n",
        "if idx in discs_pose.keys():\n",
        "    cv2.putText(cap, text=discs_pose[idx].upper(),\n",
        "                org=(int(res.landmark[25].x * cap.shape[1])\n",
        "    , int(res.landmark[0].y * cap.shape[0] + 20)), fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
        "    fontScale=0.5, color=(255,100,120), thickness=1)\n",
        "\n",
        "\n",
        "mp_drawing.draw_landmarks(cap, res, mp_pose.POSE_CONNECTIONS)\n",
        "cv2_imshow(cap)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}